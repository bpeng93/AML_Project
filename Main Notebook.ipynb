{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import scipy.misc\n",
    "import math\n",
    "import pickle\n",
    "from random import randint\n",
    "import os\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GCN(data_dir, ratio):\n",
    "    train_data = sio.loadmat(data_dir)\n",
    "    x_train = train_data['X']\n",
    "    y_train = train_data['y']\n",
    "    y_train[y_train == 10] = 0\n",
    "    x_train = x_train.transpose((3,0,1,2))\n",
    "    x_train.astype(float)\n",
    "    x_gray = np.dot(x_train, [[0.2989],[0.5870],[0.1140]])\n",
    "\n",
    "    imsize = x_gray.shape[0]\n",
    "    mean = np.mean(x_gray, axis=(1,2), dtype=float)\n",
    "    std = np.std(x_gray, axis=(1,2), dtype=float, ddof=1)\n",
    "    std[std < 1e-4] = 1\n",
    "    x_GCN = np.zeros(x_gray.shape, dtype=float)\n",
    "    for i in np.arange(imsize):\n",
    "        x_GCN[i,:,:] = (x_gray[i,:,:] - mean[i]) / std[i]\n",
    "    nums = x_GCN.shape[0]\n",
    "    x_GCN = x_GCN.reshape((nums,-1))\n",
    "    data = np.hstack((y_train,x_GCN))\n",
    "    np.random.shuffle(data)\n",
    "    cut=math.floor(nums*ratio)\n",
    "    train,val = data[:cut,:], data[cut:,:]\n",
    "\n",
    "    print(\"\\n------- GCN done -------\")\n",
    "    return train, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_SVHN(data_dir, ratio, batch_size):\n",
    "\n",
    "    train,val = GCN(data_dir, ratio)\n",
    "    img_width = 32\n",
    "    img_height = 32\n",
    "    img_depth = 1\n",
    "    label_bytes = 1\n",
    "    image_bytes = 1024\n",
    "    record_bytes = 1025\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        images_list = []\n",
    "        label_batch_list = []\n",
    "        for train_val in [train, val]:\n",
    "            q = tf.train.input_producer(train_val)\n",
    "            input_data = q.dequeue()\n",
    "\n",
    "            label = tf.slice(input_data , [0], [1])\n",
    "            label = tf.cast(label, tf.int32)\n",
    "\n",
    "            image_raw = tf.slice(input_data , [1], [1024])\n",
    "            image_raw = tf.reshape(image_raw, [1, 32, 32])\n",
    "            image = tf.transpose(image_raw, (1,2,0))\n",
    "            image = tf.cast(image, tf.float32)\n",
    "            images, label_batch = tf.train.batch([image, label],\n",
    "                                                batch_size = batch_size,\n",
    "                                                num_threads = 16,\n",
    "                                                capacity= 2000)\n",
    "\n",
    "            n_classes = 10\n",
    "            label_batch = tf.one_hot(label_batch, depth = n_classes)\n",
    "\n",
    "            label_batch_list.append(tf.reshape(label_batch, [batch_size, n_classes]))\n",
    "            images_list.append(images)\n",
    "\n",
    "\n",
    "        return images_list, label_batch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(layer_name, x, out_channels, kernel_size=[5,5], stride=[1,1,1,1]):\n",
    "    '''Convolution op wrapper, use RELU activation after convolution\n",
    "    Args:\n",
    "        layer_name: e.g. conv1, pool1...\n",
    "        x: input tensor, [batch_size, height, width, channels]\n",
    "        out_channels: number of output channels (or comvolutional kernels)\n",
    "        kernel_size: the size of convolutional kernel, VGG paper used: [3,3]\n",
    "        stride: A list of ints. 1-D of length 4. VGG paper used: [1, 1, 1, 1]\n",
    "        is_pretrain: if load pretrained parameters, freeze all conv layers.\n",
    "        Depending on different situations, you can just set part of conv layers to be freezed.\n",
    "        the parameters of freezed layers will not change when training.\n",
    "    Returns:\n",
    "        4D tensor\n",
    "    '''\n",
    "\n",
    "    in_channels = x.get_shape()[-1]\n",
    "    with tf.variable_scope(layer_name):\n",
    "        w = tf.get_variable(name='weights',\n",
    "                            shape=[kernel_size[0], kernel_size[1], in_channels, out_channels],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer()) # default is uniform distribution initialization\n",
    "        b = tf.get_variable(name='biases',\n",
    "                            shape=[out_channels],\n",
    "                            initializer=tf.constant_initializer(0.0))\n",
    "        x = tf.nn.conv2d(x, w, stride, padding='SAME', name='conv')\n",
    "        x = tf.nn.bias_add(x, b, name='bias_add')\n",
    "        x = tf.nn.relu(x, name='relu')\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pool(layer_name, x, kernel=[1,2,2,1], stride=[1,2,2,1]):\n",
    "    '''Pooling op\n",
    "    Args:\n",
    "        x: input tensor\n",
    "        kernel: pooling kernel, VGG paper used [1,2,2,1], the size of kernel is 2X2\n",
    "        stride: stride size, VGG paper used [1,2,2,1]\n",
    "        padding:'SAME'\n",
    "    '''\n",
    "    \n",
    "    x = tf.nn.max_pool(x, kernel, strides=stride, padding='SAME', name=layer_name)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def FC_layer(layer_name, x, out_nodes):\n",
    "    '''Wrapper for fully connected layers with RELU activation as default\n",
    "    Args:\n",
    "        layer_name: e.g. 'FC1', 'FC2'\n",
    "        x: input feature map\n",
    "        out_nodes: number of neurons for current FC layer\n",
    "    '''\n",
    "    shape = x.get_shape()\n",
    "    size = shape[1].value * shape[2].value * shape[3].value\n",
    "\n",
    "    with tf.variable_scope(layer_name):\n",
    "        w = tf.get_variable('weights',\n",
    "                            shape=[size, out_nodes],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('biases',\n",
    "                            shape=[out_nodes],\n",
    "                            initializer=tf.constant_initializer(0.0))\n",
    "        flat_x = tf.reshape(x, [-1, size]) # flatten into 1D\n",
    "\n",
    "        x = tf.nn.bias_add(tf.matmul(flat_x, w), b)\n",
    "        x = tf.nn.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_layer(layer_name, x, out_nodes):\n",
    "    shape = x.get_shape()\n",
    "    size = shape[-1].value\n",
    "    with tf.variable_scope(layer_name):\n",
    "        w = tf.get_variable('weights',\n",
    "                            shape=[size, out_nodes],\n",
    "                            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b = tf.get_variable('biases',\n",
    "                            shape=[out_nodes],\n",
    "                            initializer=tf.constant_initializer(0.0))\n",
    "        flat_x = tf.reshape(x, [-1, size]) # flatten into 1D\n",
    "        x = tf.nn.bias_add(tf.matmul(flat_x, w), b)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_out(layer_name, x, keep_prob = 0.5):\n",
    "    with tf.variable_scope(layer_name):\n",
    "        x = tf.nn.dropout(x, keep_prob)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lossFn(logits, labels):\n",
    "    with tf.variable_scope('loss') as scope:\n",
    "        labels = tf.cast(labels, tf.int64)\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits\\\n",
    "                        (logits=logits, labels=labels, name='loss')\n",
    "        loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "        tf.summary.scalar(scope.name+'/loss', loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracyFn(logits, labels):\n",
    "  \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "  Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor,\n",
    "  \"\"\"\n",
    "  with tf.name_scope('accuracy') as scope:\n",
    "      correct = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))\n",
    "      correct = tf.cast(correct, tf.float32)\n",
    "      accuracy = tf.reduce_mean(correct)*100.0\n",
    "      tf.summary.scalar(scope+'/accuracy', accuracy)\n",
    "  return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optimize(loss, learning_rate, global_step):\n",
    "    '''optimization, use Gradient Descent as default\n",
    "    '''\n",
    "    with tf.name_scope('optimizer'):\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "IMG_W =  32 # resize the image, if the input image is too large, training will be very slow.\n",
    "IMG_H = 32\n",
    "RATIO = 0.2 # take 20% of dataset as validation data\n",
    "BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 20\n",
    "CAPACITY = 20\n",
    "MAX_STEP = 10 # with current parameters, it is suggested to use MAX_STEP>10k\n",
    "learning_rate = 0.0001 # with current parameters, it is suggested to use learning rate<0.0001\n",
    "\n",
    "data_dir = './data/SVHN/train_32x32.mat'\n",
    "bin_dir = './data/SVHN/'\n",
    "train_log_dir = './logs/train/'\n",
    "val_log_dir = './logs/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- GCN done -------\n",
      "Step: 0, loss: 2.3284, accuracy: 6.2500%\n",
      "**  Step 0, val loss = 2.31, val accuracy = 3.12%  **\n",
      "Step: 5, loss: 2.2421, accuracy: 14.0625%\n",
      "**  Step 5, val loss = 2.29, val accuracy = 17.19%  **\n",
      "Step: 9, loss: 2.2203, accuracy: 23.4375%\n",
      "**  Step 9, val loss = 2.20, val accuracy = 25.00%  **\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('input'):\n",
    "\n",
    "    image_batch, label_batch  = read_SVHN(data_dir = data_dir,\n",
    "                                                        ratio = 0.1,\n",
    "                                                        batch_size = 64)\n",
    "    tra_image_batch = image_batch[0]\n",
    "    tra_label_batch = label_batch[0]\n",
    "\n",
    "    val_image_batch = image_batch[1]\n",
    "    val_label_batch = label_batch[1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[BATCH_SIZE, IMG_W, IMG_H, 1])\n",
    "y_ = tf.placeholder(tf.int16, shape=[BATCH_SIZE,N_CLASSES])\n",
    "\n",
    "\n",
    "c1 = conv('conv1', x, 16)\n",
    "p1 = pool('pool1', c1)\n",
    "\n",
    "c2 = conv('conv2', p1, 64)\n",
    "p2 = pool('pool2', c2)\n",
    "\n",
    "c3 = conv('conv3', p2, 128)\n",
    "p3 = pool('pool3', c3)\n",
    "\n",
    "fc = FC_layer('fc4', p3, out_nodes = 64)\n",
    "do = drop_out('drop_out', fc, keep_prob = 0.5)\n",
    "logits = final_layer('softmax', do, out_nodes=N_CLASSES)\n",
    "\n",
    "loss = lossFn(logits, y_)\n",
    "accuracy = accuracyFn(logits, y_)\n",
    "\n",
    "my_global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "train_op = optimize(loss, learning_rate, my_global_step)\n",
    "\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    tra_summary_writer = tf.summary.FileWriter(train_log_dir, sess.graph)\n",
    "    val_summary_writer = tf.summary.FileWriter(val_log_dir, sess.graph)\n",
    "\n",
    "\n",
    "    try:\n",
    "        for step in np.arange(MAX_STEP):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            tra_images,tra_labels = sess.run([tra_image_batch, tra_label_batch])\n",
    "            _, tra_loss, tra_acc = sess.run([train_op, loss, accuracy], feed_dict={x:tra_images, y_:tra_labels})\n",
    "            if step % 5 == 0 or (step + 1) == MAX_STEP:\n",
    "\n",
    "                print ('Step: %d, loss: %.4f, accuracy: %.4f%%' % (step, tra_loss, tra_acc))\n",
    "                _, summary_str = sess.run([train_op, summary_op], feed_dict={x: tra_images, y_: tra_labels})\n",
    "                tra_summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "            if step % 5 == 0 or (step + 1) == MAX_STEP:\n",
    "                val_images, val_labels = sess.run([val_image_batch, val_label_batch])\n",
    "                val_loss, val_acc = sess.run([loss, accuracy], feed_dict={x:val_images,y_:val_labels})\n",
    "\n",
    "                print('**  Step %d, val loss = %.2f, val accuracy = %.2f%%  **' %(step, val_loss, val_acc))\n",
    "                _, summary_str = sess.run([train_op, summary_op], feed_dict={x: val_images, y_: val_labels})\n",
    "                val_summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpool(value, name='unpool'):\n",
    "    \"\"\"N-dimensional version of the unpooling operation from\n",
    "    https://www.robots.ox.ac.uk/~vgg/rg/papers/Dosovitskiy_Learning_to_Generate_2015_CVPR_paper.pdf\n",
    "    :param value: A Tensor of shape [b, d0, d1, ..., dn, ch]\n",
    "    :return: A Tensor of shape [b, 2*d0, 2*d1, ..., 2*dn, ch]\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name) as scope:\n",
    "        sh = value.get_shape().as_list()\n",
    "        dim = len(sh[1:-1])\n",
    "        out = (tf.reshape(value, [-1] + sh[-dim:]))\n",
    "        for i in range(dim, 0, -1):\n",
    "            out = tf.concat([out, out],i)\n",
    "        out_size = [-1] + [s * 2 for s in sh[1:-1]] + [sh[-1]]\n",
    "        out = tf.reshape(out, out_size, name=scope)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = [v for v in tf.trainable_variables() if v.name == \"conv1/weights:0\"][0]\n",
    "\n",
    "#Reconstruction from the layer CNV-1\n",
    "featuresReLu_1 = tf.placeholder(tf.float32,[None, 16, 16, 16])\n",
    "unPool_1 = unpool(featuresReLu_1)\n",
    "unReLu_1 = tf.nn.relu(unPool_1)\n",
    "unBias_1 = unReLu_1\n",
    "#unConv = tf.nn.conv2d_transpose(unBias, W_conv1, output_shape=[1,28,28,1] , strides=[1,1,1,1], padding=\"SAME\")\n",
    "unConv_1 = tf.nn.conv2d_transpose(unBias_1, w1, output_shape=[64,32,32,1] , strides=[1,1,1,1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "    try:\n",
    "        for step in np.arange(1):\n",
    "            if coord.should_stop():\n",
    "                break\n",
    "            tra_images,tra_labels = sess.run([tra_image_batch, tra_label_batch])\n",
    "            c1_v = sess.run(c1, feed_dict={x:tra_images})\n",
    "            p1_v = sess.run(p1, feed_dict={c1:c1_v})\n",
    "            \n",
    "    except tf.errors.OutOfRangeError:\n",
    "        print('Done training -- epoch limit reached')\n",
    "\n",
    "    finally:\n",
    "        coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations1 = p1_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3ff4d2a40da7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#That means choose one image from this batch of images which feacture i can judge best.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#print (totals)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mpixelactive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munConv_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mfeaturesReLu_1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0misolated\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;31m#print(pixelactive.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m#shape of every pixelactive is (50, 28, 28, 1) batchsize=50 picsize=28*28 colors=1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m     \"\"\"\n\u001b[1;32m--> 606\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   3912\u001b[0m     \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msession\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m       raise ValueError(\"Cannot evaluate tensor using `eval()`: No default \"\n\u001b[0m\u001b[0;32m   3915\u001b[0m                        \u001b[1;34m\"session is registered. Use `with \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m                        \u001b[1;34m\"sess.as_default()` or pass an explicit session to \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot evaluate tensor using `eval()`: No default session is registered. Use `with sess.as_default()` or pass an explicit session to `eval(session=sess)`"
     ]
    }
   ],
   "source": [
    "#get every feature (1, 14, 14, 1) from activations1 than reconstruct from \n",
    "plt.figure(num='CNV1',figsize=(10,8))\n",
    "for i in range(32):\n",
    "    isolated = activations1.copy()\n",
    "    isolated[:,:,:,:i] = 0\n",
    "    isolated[:,:,:,i+1:] = 0#These two lines set all other features other than feature i to 0\n",
    "    #print (isolated.shape)\n",
    "    totals = np.sum(isolated,axis=(1,2,3))\n",
    "    best = np.argmax(totals,axis=0)\n",
    "    #These two lines are particular for batch of images.\n",
    "    #That means choose one image from this batch of images which feacture i can judge best.\n",
    "    #print (totals)\n",
    "    pixelactive = unConv_1.eval(feed_dict={featuresReLu_1: isolated})\n",
    "    #print(pixelactive.shape) \n",
    "    #shape of every pixelactive is (50, 28, 28, 1) batchsize=50 picsize=28*28 colors=1\n",
    "    plt.subplot(4,8,i+1)    \n",
    "    plt.imshow(pixelactive[best,:,:,0],cmap=\"gray\")\n",
    "    plt.axis('off') \n",
    "plt.subplots_adjust(top=0.5, bottom=0.08, left=0.10, right=0.95, hspace=0.1,\n",
    "                    wspace=0.35)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
